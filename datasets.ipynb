{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e404604d",
   "metadata": {},
   "source": [
    "# BEA-2019 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4dcb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 68616 Dev pairs: 8768\n"
     ]
    }
   ],
   "source": [
    "import re, os, pandas as pd\n",
    "\n",
    "# parse an \"A ...\" line from .m2\n",
    "A_RE = re.compile(r\"^A (\\d+) (\\d+)\\|\\|\\|[^|]*\\|\\|\\|([^|]*)\\|\\|\\|\")\n",
    "\n",
    "def apply_edits(src):\n",
    "    toks = src.split()\n",
    "    # apply collected edits (rightâ†’left so indices stay valid)\n",
    "    for s,e,repl in sorted(apply_edits.edits, key=lambda x: x[0], reverse=True):\n",
    "        repl_toks = [] if repl in (\"\", \"-NONE-\") else repl.split()\n",
    "        toks[s:e] = repl_toks\n",
    "    return \" \".join(toks)\n",
    "apply_edits.edits = []  # static holder\n",
    "\n",
    "def m2_to_pairs(path):\n",
    "    pairs, src = [], None\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if line.startswith(\"S \"):\n",
    "                # flush previous\n",
    "                if src is not None:\n",
    "                    tgt = apply_edits(src)\n",
    "                    pairs.append((src, tgt))\n",
    "                src = line[2:]\n",
    "                apply_edits.edits = []\n",
    "            elif line.startswith(\"A \"):\n",
    "                m = A_RE.match(line)\n",
    "                if m:\n",
    "                    s, e, repl = int(m.group(1)), int(m.group(2)), m.group(3).strip()\n",
    "                    apply_edits.edits.append((s, e, repl))\n",
    "            elif line == \"\":  # sentence boundary\n",
    "                if src is not None:\n",
    "                    tgt = apply_edits(src)\n",
    "                    pairs.append((src, tgt))\n",
    "                    src = None\n",
    "                    apply_edits.edits = []\n",
    "    # tail\n",
    "    if src is not None:\n",
    "        tgt = apply_edits(src)\n",
    "        pairs.append((src, tgt))\n",
    "    return pairs\n",
    "\n",
    "# ---- collect train/dev across files ----\n",
    "m2_dir = \"data/wi_locness/m2\"\n",
    "train, dev = [], []\n",
    "for fname in os.listdir(m2_dir):\n",
    "    if fname.endswith(\".m2\"):\n",
    "        path = os.path.join(m2_dir, fname)\n",
    "        if \"train\" in fname:\n",
    "            train += m2_to_pairs(path)\n",
    "        elif \"dev\" in fname:\n",
    "            dev += m2_to_pairs(path)\n",
    "\n",
    "pd.DataFrame(train, columns=[\"input_text\",\"target_text\"]).to_csv(\"bea_train.csv\", index=False)\n",
    "pd.DataFrame(dev,   columns=[\"input_text\",\"target_text\"]).to_csv(\"bea_dev.csv\",   index=False)\n",
    "\n",
    "print(\"Train pairs:\", len(train), \"Dev pairs:\", len(dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(train_pairs, columns=[\"input_text\", \"target_text\"])\n",
    "df.to_csv(\"bea_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f92ce",
   "metadata": {},
   "source": [
    "# NUCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8776f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting for access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e833d",
   "metadata": {},
   "source": [
    "# JFLEG (Similar to CONNL but CONNL is Part of NUCLE and We Don't Have Access Yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5322a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'corrections'],\n",
       "    num_rows: 748\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jfleg = load_dataset(\"jfleg\", split=\"test\")  \n",
    "jfleg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6b4c6",
   "metadata": {},
   "source": [
    "# WikiAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5cb41ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n",
       "        num_rows: 373801\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n",
       "        num_rows: 73249\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['alignment_label', 'normal_sentence_id', 'simple_sentence_id', 'normal_sentence', 'simple_sentence', 'gleu_score'],\n",
       "        num_rows: 118074\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wiki_auto = load_dataset(\n",
    "    \"chaojiang06/wiki_auto\",\n",
    "    \"default\",\n",
    "    revision=\"refs/convert/parquet\"   # <-- avoids script\n",
    ")\n",
    "\n",
    "wiki_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e027a1c",
   "metadata": {},
   "source": [
    "# ASSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19461646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['original', 'simplifications'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original', 'simplifications'],\n",
       "        num_rows: 359\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset = load_dataset(\"asset\")\n",
    "asset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
